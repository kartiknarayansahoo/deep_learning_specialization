{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartiknarayansahoo/deep_learning_specialization/blob/main/deep%20learning%20for%20audio/.ipynb_checkpoints/3.%20implementing%20neural%20network%20using%20tensorflow-checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "W_f-DhP1MSII",
        "outputId": "7d1abb91-6a4a-43f8-cb5e-9a1ea331d4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "id": "W_f-DhP1MSII",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d12288e7",
      "metadata": {
        "id": "d12288e7"
      },
      "outputs": [],
      "source": [
        "#build model\n",
        "#compile model\n",
        "#train model\n",
        "#evaluate model\n",
        "#make predictions\n",
        "\n",
        "import numpy as np\n",
        "from random import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d2cc02c6",
      "metadata": {
        "id": "d2cc02c6"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(num_samples, test_size):\n",
        "    x = np.array([[random()/2 for _ in range(2)] for _ in range(num_samples)])\n",
        "    y = np.array([[i[0] + i[1]] for i in x])\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = test_size)\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "617594cf",
      "metadata": {
        "id": "617594cf"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = generate_dataset(5000, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "168d05a4",
      "metadata": {
        "id": "168d05a4",
        "outputId": "63842e70-abb3-409d-cd04-ec024db1ff0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test: [[0.22169914 0.08640672]\n",
            " [0.3815336  0.34845958]\n",
            " [0.23954613 0.4150772 ]\n",
            " ...\n",
            " [0.38144357 0.49618025]\n",
            " [0.15353827 0.02301754]\n",
            " [0.48960151 0.35627133]]\n",
            "y_test: [[0.30810586]\n",
            " [0.72999318]\n",
            " [0.65462334]\n",
            " ...\n",
            " [0.87762382]\n",
            " [0.17655581]\n",
            " [0.84587284]]\n"
          ]
        }
      ],
      "source": [
        "print(\"x_test: {}\".format(x_test))\n",
        "print(\"y_test: {}\".format(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "495c423e",
      "metadata": {
        "id": "495c423e",
        "outputId": "ba5c6917-56c2-4539-eaff-49240177550d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0474\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0388\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0383\n",
            "Epoch 4/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0378\n",
            "Epoch 5/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0372\n",
            "Epoch 6/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0367\n",
            "Epoch 7/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0361\n",
            "Epoch 8/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0356\n",
            "Epoch 9/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0350\n",
            "Epoch 10/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0344\n",
            "Epoch 11/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0338\n",
            "Epoch 12/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0331\n",
            "Epoch 13/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0325\n",
            "Epoch 14/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0318\n",
            "Epoch 15/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0311\n",
            "Epoch 16/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0304\n",
            "Epoch 17/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0297\n",
            "Epoch 18/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0290\n",
            "Epoch 19/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0282\n",
            "Epoch 20/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0274\n",
            "Epoch 21/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0266\n",
            "Epoch 22/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0258\n",
            "Epoch 23/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0250\n",
            "Epoch 24/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0242\n",
            "Epoch 25/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0234\n",
            "Epoch 26/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0225\n",
            "Epoch 27/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0217\n",
            "Epoch 28/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0208\n",
            "Epoch 29/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0200\n",
            "Epoch 30/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0192\n",
            "Epoch 31/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0184\n",
            "Epoch 32/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0175\n",
            "Epoch 33/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0167\n",
            "Epoch 34/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0159\n",
            "Epoch 35/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0152\n",
            "Epoch 36/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0144\n",
            "Epoch 37/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0137\n",
            "Epoch 38/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0129\n",
            "Epoch 39/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0122\n",
            "Epoch 40/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0116\n",
            "Epoch 41/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0109\n",
            "Epoch 42/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0103\n",
            "Epoch 43/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0097\n",
            "Epoch 44/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0092\n",
            "Epoch 45/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0086\n",
            "Epoch 46/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0081\n",
            "Epoch 47/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0076\n",
            "Epoch 48/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0071\n",
            "Epoch 49/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0067\n",
            "Epoch 50/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0063\n",
            "Epoch 51/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0059\n",
            "Epoch 52/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0055\n",
            "Epoch 53/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0052\n",
            "Epoch 54/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0049\n",
            "Epoch 55/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0046\n",
            "Epoch 56/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0043\n",
            "Epoch 57/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0040\n",
            "Epoch 58/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0037\n",
            "Epoch 59/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.0035\n",
            "Epoch 60/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0033\n",
            "Epoch 61/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0031\n",
            "Epoch 62/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0029\n",
            "Epoch 63/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0027\n",
            "Epoch 64/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0026\n",
            "Epoch 65/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0024\n",
            "Epoch 66/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 67/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0021\n",
            "Epoch 68/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0020\n",
            "Epoch 69/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0019\n",
            "Epoch 70/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 71/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0017\n",
            "Epoch 72/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0016\n",
            "Epoch 73/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0015\n",
            "Epoch 74/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0014\n",
            "Epoch 75/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 76/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0013\n",
            "Epoch 77/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0012\n",
            "Epoch 78/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 79/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0011\n",
            "Epoch 80/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.0010\n",
            "Epoch 81/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 9.9568e-04\n",
            "Epoch 82/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 9.5202e-04\n",
            "Epoch 83/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 9.1127e-04\n",
            "Epoch 84/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 8.7351e-04\n",
            "Epoch 85/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 8.3857e-04\n",
            "Epoch 86/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 8.0624e-04\n",
            "Epoch 87/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 7.7591e-04\n",
            "Epoch 88/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 7.4789e-04\n",
            "Epoch 89/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 7.2200e-04\n",
            "Epoch 90/100\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 6.9794e-04\n",
            "Epoch 91/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 6.7566e-04\n",
            "Epoch 92/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 6.5493e-04\n",
            "Epoch 93/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 6.3572e-04\n",
            "Epoch 94/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 6.1802e-04\n",
            "Epoch 95/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 6.0141e-04\n",
            "Epoch 96/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 5.8614e-04\n",
            "Epoch 97/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 5.7212e-04\n",
            "Epoch 98/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 5.5889e-04\n",
            "Epoch 99/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 5.4663e-04\n",
            "Epoch 100/100\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 5.3533e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f297ce24b50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# build model 2->5->1\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(5, input_dim=2, activation=\"sigmoid\",),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "])\n",
        "\n",
        "# compile\n",
        "optimiser = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "model.compile(optimizer=optimiser, loss=\"MSE\")\n",
        "\n",
        "# train model\n",
        "model.fit(x_train, y_train, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "mVYkDtVRK3Jx",
        "outputId": "9e76f78a-7f1e-4346-925e-e91104471f98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mVYkDtVRK3Jx",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model\n",
        "print(\"\\n Model evaluation:\")\n",
        "model.evaluate(x_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "-omBJ9kvBMHD",
        "outputId": "f10a84da-9f0b-467e-80d2-0fa17ae9a6f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-omBJ9kvBMHD",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model evaluation:\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 4.9474e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0004947353736497462"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "data = np.array([0.1, 0.2], [0.2, 0.2])\n",
        "predictions = model.predict(data)\n",
        "\n",
        "print(\"\\n Some predictions:\")\n",
        "for d, p in zip(data, predictions):\n",
        "  print(\"{} + {} = {} \".format(d[0], d[1], d[2]))\n"
      ],
      "metadata": {
        "id": "23BawGZwKyV2"
      },
      "id": "23BawGZwKyV2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}